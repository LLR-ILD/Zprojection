{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [5, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMockData(x_range, y_range):\n",
    "    \"\"\"The additional exponentiation of the counts is to still have the nice\n",
    "    shapes even though we need to take the logarithm for the actual data\n",
    "    to display nicely.\n",
    "    \"\"\"\n",
    "    gauss = lambda x, mu, sigma: np.exp(-(x-mu)**2/2/sigma**2)\n",
    "\n",
    "    # In Z->nunu sample.\n",
    "    # sig1 = lambda x: gauss(x, 0.75, .1)\n",
    "    # bkg1 = lambda x: .04 - .02*x + .5*gauss(x, .4, .2)  + gauss(x, 0, .07) \n",
    "    sig1 = lambda x: 1 / ((1.05 - x )**2) #+ 100 * np.exp(gauss(x, 1.0, .1))\n",
    "    tmp1 = lambda x: 1 / ((0.05 + x ) * (1.01 - x )) + np.exp(2*x)\n",
    "    bkg1 = lambda x: tmp1(x) + 1e-4  #- tmp1(0)*x/(0.05 + x )\n",
    "\n",
    "    # In Z->e+e- sample.\n",
    "    # sig_y = lambda y: gauss(y, .75, .07)\n",
    "    sig_y = lambda x: 1\n",
    "    sig_2d = lambda x, y: sig1(x) * sig_y(y)\n",
    "\n",
    "    gauss2d = lambda x, y, x0, y0, sx, sy, rho: np.exp(\n",
    "        -.5*((x-x0)**2/sx**2 + 2*(x-x0)*(y-y0)/sx/sy*rho + (y-y0)**2/sy**2))\n",
    "    bkg_2d = lambda x, y: (\n",
    "        + .2/(x*y + .1)\n",
    "        + np.maximum(0, \n",
    "                3*gauss2d(x, y, .6, .15, .5, .2, .7)\n",
    "                + 2*gauss2d(x, y, .25, .75, .15, .2, -.3))\n",
    "    )\n",
    "\n",
    "    #s1d = np.exp(sig1(x_range))\n",
    "    s1d = sig1(x_range)\n",
    "    b1d = bkg1(x_range)\n",
    "    s1d = s1d / s1d.sum() * 1e4\n",
    "    b1d = b1d / b1d.sum() * 1.3e6\n",
    "\n",
    "    # Build the 2D hist.\n",
    "    X, Y = np.meshgrid(x_range, y_range)\n",
    "    s2d = sig_2d(X, Y)\n",
    "    b2d = bkg_2d(X, Y)\n",
    "    s2d = s2d / s2d.sum() * 1e4\n",
    "    b2d = b2d / b2d.sum() * 1.3e6\n",
    "\n",
    "    return s1d, b1d, s2d, b2d, s2d, b2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mock_data = False\n",
    "\n",
    "# Some tuning parameters.\n",
    "default_cut_x = .6\n",
    "\n",
    "x_range = np.linspace(0, 1, 100, endpoint=False)\n",
    "y_range = np.linspace(0, 1, 10, endpoint=False)\n",
    "X, Y = np.meshgrid(x_range, y_range)\n",
    "\n",
    "if mock_data:\n",
    "    s1d, b1d, s_e1, b_e1, s_e2, b_e2 = getMockData(x_range, y_range)\n",
    "    y_label = \"arbirtary event counts\"\n",
    "else:\n",
    "    from higgsstrahlung_adapter import getData\n",
    "    s1d, b1d, s_e1, b_e1, s_e2, b_e2 = getData(x_range, y_range)\n",
    "    y_label = \"N$_\\mathrm{ev}$ / 250 ifb\"\n",
    "\n",
    "s2d, b2d = s_e1, b_e1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting sample: $ZH \\rightarrow \\nu\\bar{\\nu} H$\n",
    "\n",
    "### Preselection\n",
    "\n",
    "1. $M_\\textrm{vis} \\in [10, 180]~\\textrm{GeV}$\n",
    "2. $M_\\textrm{miss} \\in [50, 220]~\\textrm{GeV}$\n",
    "3. $\\left| \\textrm{cos}\\theta_\\textrm{miss}\\right| < 0.99$\n",
    "4. $M_\\textrm{vis} + M_\\textrm{miss} < 247~\\textrm{GeV}$\n",
    "\n",
    "Rather loose preselection.\n",
    "The signal purity after this preselection is  O(1%).\n",
    "\n",
    "### Build a BDT\n",
    "\n",
    "When searching for the $ZH \\rightarrow \\nu\\bar{\\nu} H$ signal the assumption is that everything that is visible in the event stems from the Higgs decay.\n",
    "\n",
    "#### BDT variables\n",
    "\n",
    "e.g. # charged Hadrons, $M_\\textrm{vis} \\widehat{=} M_H$, $p_T$ of leading lepton, ...\n",
    "\n",
    "### Example illustration\n",
    "\n",
    "\n",
    "Note that the probability density functions are shown - Normalization and shape do not correspond to what is expected to be found in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw1D(ax, x, label_and_y, cut_x=0, xy_flipped=False, lim=None):\n",
    "    max_y = 0 \n",
    "    for label, y in label_and_y:\n",
    "        max_y = max(max_y, max(y))\n",
    "\n",
    "        if xy_flipped:\n",
    "            ax.plot(y, x, label=label)\n",
    "            ax.fill_betweenx(x, y, where=x>=cut_x, alpha=.5)\n",
    "        else:\n",
    "            ax.plot(x, y, label=label)\n",
    "            ax.fill_between(x, y, where=x>=cut_x, alpha=.5)\n",
    "    \n",
    "    if xy_flipped:\n",
    "        ax.hlines(cut_x, 0, max_y, color=\"black\", ls=\"--\", label=\"cut\")\n",
    "        ax.set_xlabel(y_label)\n",
    "        ax.set_xscale(\"log\")\n",
    "        if lim:\n",
    "            ax.set_xlim(lim)\n",
    "    else:\n",
    "        ax.vlines(cut_x, 0, max_y, color=\"black\", ls=\"--\", label=\"cut\")\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_yscale(\"log\")\n",
    "        if lim:\n",
    "            ax.set_ylim(lim)\n",
    "\n",
    "\n",
    "def drawNu(ax, cut_x=0):\n",
    "    x = x_range\n",
    "    label_and_y = [(\"sig\", s1d), (\"bkg\", b1d)]\n",
    "    draw1D(ax, x, label_and_y, cut_x)\n",
    "\n",
    "    ax.set_xlabel(\"BDT$_\\mathrm{H}$\")\n",
    "    ax.set_title(\"$Z \\\\rightarrow \\\\nu\\\\bar{\\\\nu}$\")\n",
    "    plt.legend()\n",
    "\n",
    "fig_nu, ax_nu = plt.subplots()\n",
    "drawNu(ax_nu, cut_x=default_cut_x)\n",
    "fig_nu.savefig(\"fig/BDT_H_nu.png\", facecolor=\"white\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference sample $ZH \\rightarrow e^+e^- H$\n",
    "\n",
    "In the analyis, both $Z \\rightarrow e^+e^-$ and $Z \\rightarrow \\mu^+\\mu^-$ events are used in the reference sample.\n",
    "This sample is used to estimate the (signal) efficiency of the cut on the BDT output (see above).\n",
    "\n",
    "After seperating the (presumed) Higgs and Z boson remnants (and a again a preselection), the distribution in the BDT output variable can be shown.\n",
    "Under the assumption that the seperation step worked well, the signal distribution has the same shape as in the $Z\\rightarrow \\nu\\bar\\nu$ Higgsstrahlung case.\n",
    "The relative normalization of the two signal curves is determined by the Z boson branching ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_eH, ax_eH = plt.subplots()\n",
    "label_and_y = [\n",
    "    (\"sig\", np.sum(s2d, axis=0)),\n",
    "    (\"bkg\", np.sum(b2d, axis=0)),\n",
    "]\n",
    "draw1D(ax_eH, x_range, label_and_y, cut_x=default_cut_x)\n",
    "ax_eH.set_xlabel(\"BDT$_\\mathrm{H}$\")\n",
    "ax_eH.set_title(\"$Z \\\\rightarrow e^+ e^-$\")\n",
    "plt.legend()\n",
    "plt.savefig(\"fig/BDT_H_e1.png\", facecolor=\"white\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional information from the Z decay\n",
    "\n",
    "In contrast to the $Z \\rightarrow \\nu \\bar\\nu$ sample we now have additional information from the Z decay available.\n",
    "\n",
    "So far this information is used to perform a strong preselection. \n",
    "It is hard to establish a notion of a _good_ preselection in this way.\n",
    "In a counting experiment we would want to optimize the selection such that it yields a high _efficiency $\\times$ purity_ and thus the smallest possible poissonian uncertainty.\n",
    "\n",
    "In this analysis we are interested in minimizing the uncertainty on the Higgstrahlung cross section $\\sigma_\\mathrm{ZH}$([LCWS proceedings](https://arxiv.org/abs/2002.06371)).\n",
    "With our approach, the dependency of $\\sigma_\\mathrm{ZH}$ on the BDT$_\\mathrm{H}$ cut and the Z-based selection is more complicated.\n",
    "Optimizing with respect to _efficiency $\\times$ purity_ will not yield ideal results.\n",
    "\n",
    "### Compressing the Z-dependent information into one dimension\n",
    "\n",
    "Employing a BDT for the Higgs-part selection means that we build a powerful one-dimensional distribution (as a representation of the space of the training variables).\n",
    "The idea is that the BDT output has a high seperating power between signal and background.\n",
    "\n",
    "In the following we want to explore what we can do if we have a one-dimensional representation of the Z$(\\rightarrow ee)$ part of the event, $f(\\mathrm{Z})$.\n",
    "This is not necessarily a complex construct (e.g. BDT).\n",
    "A simpler proposal is:\n",
    " \n",
    " $f(\\mathrm{Z}) = \\mathrm{Norm} \\cdot (M_\\textrm{ee} - 91)^2 + (M_\\textrm{recoil} - 125)^2$.\n",
    "\n",
    "An illustration of the 2-dimensional distribution of the signal in the $f(\\mathrm{Z})-\\mathrm{BDT}_\\mathrm{H}$ space is shown below.\n",
    "The gaussian form is only chosen for simplicity and not expected.\n",
    "As the decays of the Higgs boson and the Z boson in the Higgsstrahlung event are independent, the uncorrelatedness of the two dimensions is a feature that should stay true with the signal distribution from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_e_2d_signal = plt.subplots()\n",
    "\n",
    "ax_e_2d_signal.contourf(x_range, y_range, s2d, ls=\"-\")\n",
    "ax_e_2d_signal.set_xlabel(\"BDT$_\\mathrm{H}$\")\n",
    "ax_e_2d_signal.set_ylabel(\"$f(\\mathrm{Z})$\")\n",
    "fig.savefig(\"fig/H_vs_Z_signal.png\", facecolor=\"white\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the background\n",
    "\n",
    "The following figure is an artist's view of the 2-dimensional distributions of signal and background in the $Z \\rightarrow e^+e^-$ sample.\n",
    "\n",
    "The background distribution is shown as colored contour areas.\n",
    "The signal distribution is superimposed as contour lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawHZ(ax, cut_x=0, cut_y=0):\n",
    "    def logZ(z):\n",
    "        log_z = np.log(z)\n",
    "        log_z[log_z == -np.inf] = min(log_z[log_z != - np.inf])\n",
    "        return log_z\n",
    "\n",
    "    ax.set_xlabel(\"BDT$_\\mathrm{H}$\")\n",
    "    ax.set_ylabel(\"$f(\\mathrm{Z})$\")\n",
    "    ax.contourf(x_range, y_range, logZ(b2d))\n",
    "\n",
    "    z = logZ(s2d)\n",
    "    z[z < 1e-3*z.max()] = 0 # To avoid drawing artifacts from low statistics.\n",
    "    ax.contour(X, Y, z)\n",
    "\n",
    "\n",
    "    ax.fill_between(x_range, cut_y, \n",
    "        alpha=.75, facecolor=\"white\", hatch=\"/\", edgecolor=\"black\")#\"red\")\n",
    "    ax.vlines(cut_x, cut_y, max(y_range), color=\"black\", ls=\"--\")\n",
    "\n",
    "fig, ax_e_2d = plt.subplots()\n",
    "drawHZ(ax_e_2d, 0, 0)\n",
    "\n",
    "fig.savefig(\"fig/H_vs_Z_all.png\", facecolor=\"white\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def allRegionsPlot(cut_x=0, cut_y=0):\n",
    "    fig = plt.figure(figsize=(7, 8))\n",
    "    grid = plt.GridSpec(5, 4, hspace=0.3, wspace=0.3)\n",
    "    ax_main = fig.add_subplot(grid[2:, :-1])\n",
    "    ax_x_pdf1 = fig.add_subplot(grid[0, :-1], sharex=ax_main)\n",
    "    ax_x_pdf2 = fig.add_subplot(grid[1, :-1], sharex=ax_main)\n",
    "    ax_y_pdf  = fig.add_subplot(grid[2:, -1], sharey=ax_main)\n",
    "\n",
    "    plt.setp(ax_x_pdf1.get_xticklabels(), visible=False)\n",
    "    plt.setp(ax_x_pdf2.get_xticklabels(), visible=False)\n",
    "    plt.setp(ax_y_pdf.get_yticklabels(), visible=False)\n",
    "    \n",
    "    drawHZ(ax_main, cut_x, cut_y)\n",
    "\n",
    "    nu_label_and_y = [(\"sig\", s1d), (\"bkg\", b1d)]\n",
    "\n",
    "    idx_cut_x = np.argwhere(x_range >= cut_x)[0][0]\n",
    "    idx_cut_y = np.argwhere(y_range >= cut_y)[0][0]\n",
    "    \n",
    "    eH_label_and_y = [\n",
    "        (\"sig\", np.sum(s2d[idx_cut_y:, :], axis=0)),\n",
    "        (\"bkg\", np.sum(b2d[idx_cut_y:, :], axis=0)),\n",
    "    ]\n",
    "    eZ_label_and_y = [\n",
    "        (\"sig\", np.sum(s2d[:, idx_cut_x:], axis=1)),\n",
    "        (\"bkg\", np.sum(b2d[:, idx_cut_x:], axis=1)),\n",
    "    ]\n",
    "    nu_lim = (.1, 1.5*b1d.max())\n",
    "    eH_lim = (.1, 1.5*np.sum(b2d, axis=0).max())\n",
    "    eZ_lim = (.1, 1.5*np.sum(b2d, axis=1).max())\n",
    "    draw1D(ax_x_pdf1, x_range, nu_label_and_y, cut_x, lim=nu_lim)\n",
    "    draw1D(ax_x_pdf2, x_range, eH_label_and_y, cut_x, lim=eH_lim)\n",
    "    draw1D(ax_y_pdf,  y_range, eZ_label_and_y, cut_y, xy_flipped=True, lim=eZ_lim)\n",
    "\n",
    "    ax_x_pdf1.set_title(\"$Z \\\\rightarrow \\\\nu\\\\bar{\\\\nu}$\", fontsize=8)\n",
    "    ax_x_pdf2.set_title(\"$Z \\\\rightarrow e^+e^-$\", fontsize=8)\n",
    "    ax_y_pdf.set_title(\"$Z \\\\rightarrow e^+e^-$\", fontsize=8)\n",
    "    ax_x_pdf1.legend(loc=\"upper left\")\n",
    "    return fig\n",
    "\n",
    "#for cut_x, cut_y in itertools.product(np.arange(0, 1, .1), np.arange(0, 1, .1)):\n",
    "for cut_x, cut_y in [(.5, .5)]:\n",
    "    fig = allRegionsPlot(cut_x, cut_y)\n",
    "    fig.savefig(f\"fig/all_regions/x{cut_x:.2f}_x{cut_y:.2f}.png\", facecolor=\"white\", dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!convert -delay 100 -loop 0 -limit disk 4GiB fig/all_regions/*_x0.2.png fig/all_regions.gif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actually count the entries per region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts = []\n",
    "# for cut_x, cut_y in itertools.product(np.arange(0, 1, .01), np.arange(0, 1, .1)):\n",
    "for cut_nu, cut_e1, cut_e2 in itertools.product(x_range, y_range, y_range):\n",
    "    N = {}\n",
    "    N[\"H\"] = cut_nu\n",
    "    N[\"Z_e1\"] = cut_e1\n",
    "    N[\"Z_e2\"] = cut_e2\n",
    "    idx_cut_nu = np.argwhere(x_range >= cut_nu)[0][0]\n",
    "    idx_cut_e1 = np.argwhere(y_range >= cut_e1)[0][0]\n",
    "    idx_cut_e2 = np.argwhere(y_range >= cut_e2)[0][0]\n",
    "\n",
    "    N[\"s_nu\"] = np.sum(s1d[idx_cut_nu:])\n",
    "    N[\"b_nu\"] = np.sum(b1d[idx_cut_nu:])\n",
    "\n",
    "    N[\"s_e1\"] = np.sum(s_e1[idx_cut_e1:, idx_cut_nu:])\n",
    "    N[\"b_e1\"] = np.sum(b_e1[idx_cut_e1:, idx_cut_nu:])\n",
    "    N[\"s_e1_not\"] = np.sum(s_e1[idx_cut_e1:, :idx_cut_nu])\n",
    "    N[\"b_e1_not\"] = np.sum(b_e1[idx_cut_e1:, :idx_cut_nu])\n",
    "\n",
    "    N[\"s_e2\"] = np.sum(s_e2[idx_cut_e2:, idx_cut_nu:])\n",
    "    N[\"b_e2\"] = np.sum(b_e2[idx_cut_e2:, idx_cut_nu:])\n",
    "    N[\"s_e2_not\"] = np.sum(s_e2[idx_cut_e2:, :idx_cut_nu])\n",
    "    N[\"b_e2_not\"] = np.sum(b_e2[idx_cut_e2:, :idx_cut_nu])\n",
    "    all_counts.append(N)\n",
    "N = pd.DataFrame(all_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getEffUnc(N, z_decays):\n",
    "    if isinstance(z_decays, str): z_decays = list(z_decays)\n",
    "\n",
    "    s = sum(N[\"s_\"+z_dec] for z_dec in z_decays)\n",
    "    b = sum(N[\"b_\"+z_dec] for z_dec in z_decays)\n",
    "    s_not = sum(N[\"s_\"+z_dec+\"_not\"] for z_dec in z_decays)\n",
    "    b_not = sum(N[\"b_\"+z_dec+\"_not\"] for z_dec in z_decays)\n",
    "\n",
    "    eff_unc = (\n",
    "        (s + s_not + b + b_not) / (s + s_not)**2\n",
    "        + (s + b) / s**2\n",
    "        - 2*(s + b) / (s * (s + s_not))\n",
    "    )**.5\n",
    "    return eff_unc\n",
    "\n",
    "N[\"counting_unc\"] = ((N.s_nu + N.b_nu) / N.s_nu ** 2)**.5 #*5 # 5**2 N_WWH = 0.2*N_nnH\n",
    "N[\"efficiency_unc\"] = getEffUnc(N, [\"e1\", \"e2\"])\n",
    "N[\"cs_unc\"] = (N[\"counting_unc\"]**2 + N[\"efficiency_unc\"]**2)**.5\n",
    "\n",
    "\n",
    "N[\"eff_unc_e1\"] = getEffUnc(N, [\"e1\"])\n",
    "N[\"cs_unc_e1\"] = (N[\"counting_unc\"]**2 + N[\"eff_unc_e1\"]**2)**.5\n",
    "N[\"eff_unc_e2\"] = getEffUnc(N, [\"e2\"])\n",
    "N[\"cs_unc_e2\"] = (N[\"counting_unc\"]**2 + N[\"eff_unc_e2\"]**2)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(N.counting_unc.min())\n",
    "print(N.cs_unc.min())\n",
    "\n",
    "print(N.cs_unc_e1.min())\n",
    "print(N.cs_unc_e2.min())\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N[N.cs_unc < .2][[\"counting_unc\", \"efficiency_unc\", \"cs_unc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unc in [\n",
    "    \"counting_unc\", \n",
    "    \"efficiency_unc\", \n",
    "    \"cs_unc\"\n",
    "]:\n",
    "    (100*N[N.cs_unc < .2][unc]).plot(label=unc)\n",
    "plt.legend()\n",
    "# plt.yscale(\"log\")\n",
    "#plt.xticks(np.arange(0, len(N)+1, 10))\n",
    "plt.grid()\n",
    "#plt.ylim((0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unc = []\n",
    "N_unc = []\n",
    "eff_unc = []\n",
    "for x, df in N.groupby(\"H\"):\n",
    "    idx = df[\"cs_unc\"].idxmin()\n",
    "    unc.append(N.iloc[idx][\"cs_unc\"])\n",
    "    eff_unc.append(N.iloc[idx][\"efficiency_unc\"])\n",
    "    N_unc.append(N.iloc[idx][\"counting_unc\"])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "x = np.linspace(0, 1, len(unc))\n",
    "ax.plot(x, 100*np.array(unc),     label=f\"total ({100*min(unc):.1f}%)\")\n",
    "ax.plot(x, 100*np.array(N_unc),   label=f\"N ({100*min(N_unc):.1f}%)\")\n",
    "ax.plot(x, 100*np.array(eff_unc), label=f\"ε ({100*min(eff_unc):.1f}%)\")\n",
    "ax.legend(title=\"Uncertainty part (minimum)\")\n",
    "ax.set_xlabel(\"BDT$_H$ selection cut\")\n",
    "ax.set_ylabel(\"realtive unc. [%]\")\n",
    "ax.set_ylim([0, 7])\n",
    "ax.grid()\n",
    "ax.set_title(\"ννH cross section from 250 fb$^{-1}$ ILC$_{right}$\")\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"/home/kunath/ILD_vvH_DBD_vs_MC2020/doc/fig/new_ext_nnH_cs_uncertainty.png\", facecolor=\"white\", dpi=300)\n",
    "# fig.savefig(\"/home/kunath/minisoutenance/img/new_ext_nnH_cs_uncertainty.png\", facecolor=None, dpi=300)\n",
    "fig.savefig(\"fig/new_ext_nnH_cs_uncertainty.png\", facecolor=None, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N.to_pickle(\"data/N.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b647f36ca438a0abe93235837e3dd95bfad2ab5ce8629a0cf0e1a667d24e6a25"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('myLCBoost': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
